{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96aaa01",
   "metadata": {},
   "source": [
    "1. Quadratic equation solver\n",
    "\n",
    "This part of project demonstrates conditional workflows in LangGraph through a quadratic equation solver, where execution paths dynamically branch based on discriminant values. Note goal here is to first see how to create conditional edges and later in 2nd part will make more complex graph with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55e69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5700bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a state type for our graph\n",
    "class QuadState(TypedDict):\n",
    "    a: int\n",
    "    b: int\n",
    "    c: int\n",
    "\n",
    "    equation: str\n",
    "    discriminant: float\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5720c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes\n",
    "def show_equation(state: QuadState):\n",
    "\n",
    "    equation = f'{state[\"a\"]}x2{state[\"b\"]}x{state[\"c\"]}'\n",
    "\n",
    "    return {'equation':equation}\n",
    "\n",
    "def calculate_discriminant(state: QuadState):\n",
    "\n",
    "    discriminant = state[\"b\"]**2 - (4*state[\"a\"]*state[\"c\"])\n",
    "\n",
    "    return {'discriminant': discriminant}\n",
    "\n",
    "def real_roots(state: QuadState):\n",
    "\n",
    "    root1 = (-state[\"b\"] + state[\"discriminant\"]**0.5)/(2*state[\"a\"])\n",
    "    root2 = (-state[\"b\"] - state[\"discriminant\"]**0.5)/(2*state[\"a\"])\n",
    "\n",
    "    result = f'The roots are {root1} and {root2}'\n",
    "\n",
    "    return {'result': result}\n",
    "\n",
    "def repeated_roots(state: QuadState):\n",
    "\n",
    "    root = (-state[\"b\"])/(2*state[\"a\"])\n",
    "\n",
    "    result = f'Only repeating root is {root}'\n",
    "\n",
    "    return {'result': result}\n",
    "\n",
    "def no_real_roots(state: QuadState):\n",
    "\n",
    "    result = f'No real roots'\n",
    "\n",
    "    return {'result': result}\n",
    "\n",
    "# for conditional branching, we need to return a literal string\n",
    "# that matches the name of the next node\n",
    "# kind of routing node\n",
    "def check_condition(state: QuadState) -> Literal[\"real_roots\", \"repeated_roots\", \"no_real_roots\"]:\n",
    "\n",
    "    if state['discriminant'] > 0:\n",
    "        return \"real_roots\"\n",
    "    elif state['discriminant'] == 0:\n",
    "        return \"repeated_roots\"\n",
    "    else:\n",
    "        return \"no_real_roots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb28ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(QuadState)\n",
    "\n",
    "graph.add_node('show_equation', show_equation)\n",
    "graph.add_node('calculate_discriminant', calculate_discriminant)\n",
    "graph.add_node('real_roots', real_roots)\n",
    "graph.add_node('repeated_roots', repeated_roots)\n",
    "graph.add_node('no_real_roots', no_real_roots)\n",
    "\n",
    "\n",
    "graph.add_edge(START, 'show_equation')\n",
    "graph.add_edge('show_equation', 'calculate_discriminant')\n",
    "\n",
    "graph.add_conditional_edges('calculate_discriminant', check_condition)\n",
    "graph.add_edge('real_roots', END)\n",
    "graph.add_edge('repeated_roots', END)\n",
    "graph.add_edge('no_real_roots', END)\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# visualize\n",
    "try:\n",
    "    from IPython.display import Image\n",
    "    Image(workflow.get_graph().draw_mermaid_png())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f732fa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tshow_equation(show_equation)\n",
      "\tcalculate_discriminant(calculate_discriminant)\n",
      "\treal_roots(real_roots)\n",
      "\trepeated_roots(repeated_roots)\n",
      "\tno_real_roots(no_real_roots)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> show_equation;\n",
      "\tcalculate_discriminant -.-> no_real_roots;\n",
      "\tcalculate_discriminant -.-> real_roots;\n",
      "\tcalculate_discriminant -.-> repeated_roots;\n",
      "\tshow_equation --> calculate_discriminant;\n",
      "\tno_real_roots --> __end__;\n",
      "\treal_roots --> __end__;\n",
      "\trepeated_roots --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can visualize the graph using mermaid syntax\n",
    "# https://mermaid.live/\n",
    "# sometime due to network issues, image may not render, in that case use mermaid_code below to visualize\n",
    "\n",
    "mermaid_code = workflow.get_graph().draw_mermaid()\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbf10cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2,\n",
       " 'b': 4,\n",
       " 'c': 2,\n",
       " 'equation': '2x24x2',\n",
       " 'discriminant': 0,\n",
       " 'result': 'Only repeating root is -1.0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'a': 2, \n",
    "    'b': 4,\n",
    "    'c': 2\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb9061",
   "metadata": {},
   "source": [
    "2. Review Reply Workflow\n",
    "\n",
    "An LLM-powered conditional workflow in LangGraph that analyzes customer reviews and dynamically generates context-aware replies based on sentiment and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eac2242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd2882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define schemas for sentiment analysis and diagnosis\n",
    "\n",
    "class SentimentSchema(BaseModel):\n",
    "\n",
    "    # Literal is used when you want a variable (or function parameter) to accept only specific, \n",
    "    # fixed values instead of any value of a type.\n",
    "    # Here, we restrict sentiment to be either \"positive\" or \"negative\"\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description='Sentiment of the review')\n",
    "\n",
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65088dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for structured output, we need to create a structured model\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2 = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ac4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define State\n",
    "class ReviewState(TypedDict):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe0033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nodes\n",
    "\n",
    "def find_sentiment(state: ReviewState):\n",
    "\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}\n",
    "\n",
    "# conditional branching node\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "\n",
    "def positive_response(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Write a warm thank-you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "\n",
    "    # response is in json, so we convert to dict\n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message. Just write response message, no subjectes or greetings.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b3e758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make graph, add nodes and edges\n",
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "\n",
    "graph.add_edge('positive_response', END)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16dbfd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "try:\n",
    "    from IPython.display import Image\n",
    "    Image(workflow.get_graph().draw_mermaid_png())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3513e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tfind_sentiment(find_sentiment)\n",
      "\tpositive_response(positive_response)\n",
      "\trun_diagnosis(run_diagnosis)\n",
      "\tnegative_response(negative_response)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> find_sentiment;\n",
      "\tfind_sentiment -.-> positive_response;\n",
      "\tfind_sentiment -.-> run_diagnosis;\n",
      "\trun_diagnosis --> negative_response;\n",
      "\tnegative_response --> __end__;\n",
      "\tpositive_response --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can visualize the graph using mermaid syntax\n",
    "# https://mermaid.live/\n",
    "# sometime due to network issues, image may not render, in that case use mermaid_code below to visualize\n",
    "\n",
    "mermaid_code = workflow.get_graph().draw_mermaid()\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ae52f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Bug', 'tone': 'frustrated', 'urgency': 'high'},\n",
       " 'response': \"I understand how frustrating it can be to deal with a bug, especially when it impacts your work. I appreciate your patience as we work to resolve this. To help us tackle the issue effectively, could you please provide me with a few details? Specifically, let me know what the bug is, any error messages you're seeing, and the steps you've taken so far. This information will help me assist you more efficiently. Thank you for your understanding, and I’m here to help get this sorted out for you as quickly as possible.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intial_state={\n",
    "    'review': \"I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(intial_state)\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "984d1124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I understand how frustrating it can be to deal with a bug, especially when it impacts your work. I appreciate your patience as we work to resolve this. To help us tackle the issue effectively, could you please provide me with a few details? Specifically, let me know what the bug is, any error messages you're seeing, and the steps you've taken so far. This information will help me assist you more efficiently. Thank you for your understanding, and I’m here to help get this sorted out for you as quickly as possible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see response in cleaner format\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(final_state['response']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
